{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.metrics import adjusted_mutual_info_score, mutual_info_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.DataFrame(); target_cols = []; rep_cols=[]\n",
    "exist_cond = lambda x: isinstance(x,pd.DataFrame) and x.shape[1]>0 \n",
    "rep_report_df = None\n",
    "rep_dummy_cols_map = {}\n",
    "clus_dummies = df_corr[target_cols]\n",
    "\n",
    "for g_ind, group in enumerate(rep_cols):\n",
    "    rep_dummy_cols=[]\n",
    "    cols_to_concat_f = [k[1].iloc[train_ind] for k in group if k and exist_cond(k[1]) ]\n",
    "    cols_to_concat_c = [k[0].iloc[train_ind] for k in group if k and exist_cond(k[0]) ]\n",
    "\n",
    "    if cols_to_concat_c: \n",
    "        clusters_tiled_c = pd.concat([clus_dummies]*len(cols_to_concat_c), ignore_index=True,sort=False)\n",
    "        cols_concat_c = pd.concat(cols_to_concat_c, axis=0, ignore_index=True,sort=False)\n",
    "    if cols_to_concat_f: \n",
    "        clusters_tiled_f = pd.concat([clus_dummies]*len(cols_to_concat_f), ignore_index=True,sort=False)\n",
    "        rep_t_float_vars = pd.concat(cols_to_concat_f, axis=0, ignore_index=True,sort=False)\n",
    "        rep_df_MI_X = rep_t_float_vars.copy()\n",
    "    else:\n",
    "        rep_df_MI_X = pd.DataFrame(index=cols_concat_c.index)\n",
    "\n",
    "    col_sfx = str(g_ind)+'.'\n",
    "    for k in list(cols_concat_c.columns):\n",
    "        cols_concat_c[k] = cols_concat_c[k].astype('category')\n",
    "        for val in cols_concat_c[k].cat.categories:\n",
    "            rep_df_MI_X[col_sfx+ k+'|'+str(val)] = (cols_concat_c[k] == val).astype('int32').astype('category')\n",
    "            rep_dummy_cols.append(col_sfx+k+'|'+str(val))\n",
    "            rep_dummy_cols_map[col_sfx+k+'|'+str(val)] = k+'|'+str(val) + '|'+', '.join([a for a,b in categs_json[k].items() if b ==int(val)]) \n",
    "\n",
    "#     rep_report_df = pd.DataFrame(index = rep_df_MI_X.columns)\n",
    "    discrete_flag = (\n",
    "        ([True]*rep_t_float_vars.shape[1] if cols_to_concat_f else []) +\n",
    "        ([False]*len(rep_dummy_cols) if cols_to_concat_c else [])\n",
    "    )\n",
    "\n",
    "    temp_df = pd.DataFrame(index= rep_df_MI_X.columns)\n",
    "    for ii,clus in enumerate(target_cols):\n",
    "\n",
    "        if clus == 18 and g_ind == 4: \n",
    "            ipdb.set_trace()\n",
    "        temp_df[clus+'_MI'] = mutual_info_regression(\n",
    "            rep_df_MI_X.astype('float64').fillna(0).values,\n",
    "            clusters_tiled_c[clus].astype('float64'), \n",
    "            discrete_features=discrete_flag\n",
    "        )\n",
    "        temp_df[clus+'_COR'] = rep_df_MI_X.astype('float64').fillna(0).corrwith(clusters_tiled_c[clus])\n",
    "\n",
    "        # categ vars \n",
    "        if cols_to_concat_c:\n",
    "            c_stats = np.zeros((len(rep_dummy_cols),2))\n",
    "            for id1, lb1 in enumerate(rep_dummy_cols): \n",
    "                total_lb1 = (rep_df_MI_X[lb1] == 1).sum()\n",
    "                total_cl = (clusters_tiled_c[clus] == 1).sum()\n",
    "                c_stats[id1,0] = (\n",
    "                    ((rep_df_MI_X[lb1] == 1)&(clusters_tiled_c[clus] == 1)).sum() / total_lb1\n",
    "                ) if total_lb1>0 else -99\n",
    "                c_stats[id1,1] = (\n",
    "                    ((rep_df_MI_X[lb1] == 1)&(clusters_tiled_c[clus] == 1)).sum() / total_cl\n",
    "                ) if total_cl>0 else -99\n",
    "            c_stats = pd.DataFrame(c_stats,index =rep_dummy_cols,  columns=[clus + s for s in ['_(%)Label','_(%)Cluster']])\n",
    "            temp_df = pd.concat([temp_df,c_stats],axis=1,sort=False)\n",
    "\n",
    "        # float vars\n",
    "        if cols_to_concat_f:\n",
    "            cls_float_vals = rep_t_float_vars[(clusters_tiled_f[clus]==1).values]\n",
    "            quartile_cols = [f'{clus}_Q{100*quantile_1:.3}%', f'{clus}_Q{100*quantile_2:.3}%']\n",
    "            temp_df[quartile_cols]  = cls_float_vals.quantile([quantile_1,quantile_2]).T\n",
    "            temp_df[clus+'_MEAN'] = cls_float_vals.mean()\n",
    "            temp_df[clus+'_NON_NAN'] = cls_float_vals.count() / (clusters_tiled_f[clus]==1).values.sum()\n",
    "            np_q_perc = np.zeros(temp_df.shape[0])\n",
    "\n",
    "            for f_idx, f_col in enumerate(rep_t_float_vars):\n",
    "                q_bool = (\n",
    "                    (rep_t_float_vars[f_col]>=temp_df.loc[f_col,quartile_cols[0]]) &(rep_t_float_vars[f_col]<=temp_df.loc[f_col,quartile_cols[1]])\n",
    "                ).values\n",
    "                qbs = q_bool.sum()\n",
    "                np_q_perc[f_idx] = ((q_bool & (clusters_tiled_f[clus]==1).values).sum() / qbs) if qbs>0 else -99\n",
    "            temp_df[clus+'_(%)Percentile'] = np_q_perc\n",
    "\n",
    "    temp_df['categ_long'] = pd.Series([rep_dummy_cols_map[k] if k in rep_dummy_cols_map else '-' for k in temp_df.index ],index=temp_df.index)    \n",
    "    if not isinstance(rep_report_df, pd.DataFrame): rep_report_df=temp_df\n",
    "    else: rep_report_df=rep_report_df.append(temp_df,sort=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
